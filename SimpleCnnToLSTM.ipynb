{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from torchvision.datasets import Flickr8k\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_transform(size):\n",
    "    def inner(image):\n",
    "        return transforms.ToTensor()(image.resize((size, size)))\n",
    "    return inner\n",
    "\n",
    "def target_transform(targets):\n",
    "    target = targets[0].lower()\n",
    "    target = target.translate(str.maketrans('', '', string.punctuation))\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(batch_size=64, image_size=256, prop=0.9):\n",
    "    data = Flickr8k('Flickr8k/Flicker8k_Dataset', ann_file='Flickr8k/8k-pictures.html',\n",
    "                transform=im_transform(image_size), target_transform=target_transform)\n",
    "    inds = list(range(len(data)))\n",
    "    split1 = int(np.floor(prop * len(inds)))\n",
    "    split2 = int(np.floor(prop * split1))\n",
    "    np.random.shuffle(inds)\n",
    "        \n",
    "    train_inds = inds[:split2]\n",
    "    valid_inds = inds[split2:split1]\n",
    "    test_inds = inds[split1:]\n",
    "    \n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_inds)\n",
    "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_inds)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_inds)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, \n",
    "                                       sampler=train_sampler, num_workers=0)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, \n",
    "                                       sampler=valid_sampler, num_workers=0)\n",
    "    test_dataloader = torch.utils.data.DataLoader(data, batch_size=batch_size, \n",
    "                                       sampler=valid_sampler, num_workers=0)\n",
    "    return train_dataloader, valid_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, valid_dataloader, test_dataloader = train_valid_test_split(image_size=256, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind = {'<START>': 0, '<END>': 1, '<UNK>': 2, '<PAD>': 3}\n",
    "ind2word = ['<START>', '<END>', '<UNK>', '<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for X, y in train_dataloader:\n",
    "    for seq in y:\n",
    "        target = nltk.tokenize.word_tokenize(seq)\n",
    "        for word in target:\n",
    "            if word not in ind2word:\n",
    "                word2ind[word] = len(ind2word)\n",
    "                ind2word.append(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, преобразующая набор строк в матричку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_capt_transform(batch, seq_len=20):\n",
    "    seqs = [None] * len(batch)\n",
    "    for i in range(len(batch)):\n",
    "        seq = nltk.tokenize.word_tokenize(batch[i])\n",
    "        seq.append('<END>')\n",
    "        seq.insert(0, '<START>')\n",
    "        \n",
    "        seqs[i] = [word2ind['<PAD>']] * seq_len\n",
    "        for j, word in enumerate(seq):\n",
    "            if j > len(seqs[i]) - 1:\n",
    "                break\n",
    "            if word in word2ind:\n",
    "                seqs[i][j] = word2ind[word]\n",
    "            else:\n",
    "                seqs[i][j] = word2ind['<UNK>']\n",
    "        \n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two bums are sitting on a sidewalk outside a peace mission in portland oregon\n",
      "[0, 18, 1627, 198, 269, 23, 4, 309, 260, 4, 810, 1628, 42, 1629, 1630, 1, 3, 3, 3, 3]\n",
      "a dog catching a biscuit in its mouth\n",
      "[0, 4, 6, 548, 4, 3166, 42, 282, 87, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man in a checked shirt stands next to a large wooden bowl\n",
      "[0, 4, 41, 42, 4, 1169, 80, 61, 311, 48, 4, 43, 9, 1318, 1, 3, 3, 3, 3, 3]\n",
      "a person wearing skis makes a jump over the snow\n",
      "[0, 4, 167, 57, 536, 217, 4, 222, 193, 21, 92, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a brown dog picks up a twig from a stone surface\n",
      "[0, 4, 32, 6, 2124, 28, 4, 2125, 8, 4, 861, 307, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man and woman are sitting on concrete stairs\n",
      "[0, 4, 41, 29, 243, 198, 269, 23, 613, 876, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a medium brown dog is jumping over a short brick wall surrounding some dirt\n",
      "[0, 4, 707, 32, 6, 25, 7, 193, 4, 244, 360, 320, 2072, 38, 93, 1, 3, 3, 3, 3]\n",
      "men in drak outfits around acampfire\n",
      "[0, 204, 42, 3653, 148, 153, 3654, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man and 2 women in dark clothing\n",
      "[0, 4, 41, 29, 191, 442, 42, 267, 216, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man fly fishes in a large river\n",
      "[0, 4, 41, 1266, 3090, 42, 4, 43, 448, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a black and white dog is drooling whilst walking on the grass\n",
      "[0, 4, 5, 29, 85, 6, 25, 3428, 949, 184, 23, 21, 129, 1, 3, 3, 3, 3, 3, 3]\n",
      "a couple walking alongside a waterfront next to a city\n",
      "[0, 4, 102, 184, 1006, 4, 1007, 311, 48, 4, 483, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a little boy kicks a soccer ball in the park\n",
      "[0, 4, 274, 13, 844, 4, 517, 164, 42, 21, 428, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man in a red uniform jumps towards a soccer ball\n",
      "[0, 4, 41, 42, 4, 44, 108, 14, 551, 4, 517, 164, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "two blonde boys are playing on a bed\n",
      "[0, 18, 364, 467, 198, 387, 23, 4, 670, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a woman carrying a backpack sits on a rocky ledge overlooking the water\n",
      "[0, 4, 243, 225, 4, 623, 365, 23, 4, 96, 315, 180, 21, 15, 1, 3, 3, 3, 3, 3]\n",
      "a group of people jump into a lake in unison\n",
      "[0, 4, 406, 112, 152, 222, 11, 4, 12, 42, 2546, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "two girls in blue dresses dance\n",
      "[0, 18, 764, 42, 31, 1041, 384, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a boy in blue shorts with yellow stripes down the sides is leaping\n",
      "[0, 4, 13, 42, 31, 207, 63, 206, 1460, 116, 21, 923, 25, 926, 1, 3, 3, 3, 3, 3]\n",
      "a girl reads and listens to music on a bus\n",
      "[0, 4, 56, 426, 29, 2920, 48, 2027, 23, 4, 1803, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a girl in a dark shirt has stripes painted under her eyes while another girl stands in the foreground\n",
      "[0, 4, 56, 42, 4, 267, 80, 606, 1460, 1316, 863, 185, 415, 50, 211, 56, 61, 42, 21, 3073]\n",
      "a baby reaching into a water fountain\n",
      "[0, 4, 258, 1145, 11, 4, 15, 310, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a bearded man laying on his back under a large tree\n",
      "[0, 4, 845, 41, 430, 23, 73, 675, 863, 4, 43, 650, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "two big dogs wade in the ocean\n",
      "[0, 18, 280, 33, 3636, 42, 21, 254, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a boy leans on a baseball bat and holds out one arm outstreached\n",
      "[0, 4, 13, 734, 23, 4, 338, 142, 29, 281, 284, 205, 629, 2369, 1, 3, 3, 3, 3, 3]\n",
      "a baseball player throws the ball\n",
      "[0, 4, 338, 263, 227, 21, 164, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a skinny girl rides by on a bike with a lot of people in the background\n",
      "[0, 4, 2339, 56, 95, 37, 23, 4, 98, 63, 4, 500, 112, 152, 42, 21, 65, 1, 3, 3]\n",
      "a boy playing basketball trying to block a shot\n",
      "[0, 4, 13, 387, 233, 654, 48, 323, 4, 479, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a black dog and a brown dog playing in tall weeds\n",
      "[0, 4, 5, 6, 29, 4, 32, 6, 387, 42, 2031, 2491, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "two gray dogs run together over the green grass\n",
      "[0, 18, 607, 33, 746, 416, 193, 21, 160, 129, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a bunch of men playing rugby\n",
      "[0, 4, 169, 112, 204, 387, 1273, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a group of people sitting on benches at a city park\n",
      "[0, 4, 406, 112, 152, 269, 23, 2522, 139, 4, 483, 428, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "a wet white dog is splashing in the water with a stick in its mouth\n",
      "[0, 4, 351, 85, 6, 25, 678, 42, 21, 15, 63, 4, 86, 42, 282, 87, 1, 3, 3, 3]\n",
      "a white dog catching a soccer ball midair\n",
      "[0, 4, 85, 6, 548, 4, 517, 164, 150, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a dog biting the tail of a cow\n",
      "[0, 4, 6, 418, 21, 899, 112, 4, 409, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a brown dog is chasing a ball on the grass\n",
      "[0, 4, 32, 6, 25, 163, 4, 164, 23, 21, 129, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a fisherman stands on the beach on a gray day\n",
      "[0, 4, 1673, 61, 23, 21, 24, 23, 4, 607, 1545, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man with an afro propels his skateboard into the air\n",
      "[0, 4, 41, 63, 131, 2317, 2726, 73, 316, 11, 21, 308, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "a guy and a girl jumping up in the air\n",
      "[0, 4, 584, 29, 4, 56, 7, 28, 42, 21, 308, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a black dog splashes through greenish water\n",
      "[0, 4, 5, 6, 587, 165, 3220, 15, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a brown dog is running across the snowy ground\n",
      "[0, 4, 32, 6, 25, 91, 379, 21, 126, 775, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man holds a boy upside down over a pond\n",
      "[0, 4, 41, 281, 4, 13, 549, 116, 193, 4, 459, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a little white curly haired dog runs across the pavement with a stick in its mouth\n",
      "[0, 4, 274, 85, 1106, 743, 6, 296, 379, 21, 1029, 63, 4, 86, 42, 282, 87, 1, 3, 3]\n",
      "a person in a blue jacket wearing a bicycle helmet is riding a bike\n",
      "[0, 4, 167, 42, 4, 31, 109, 57, 4, 342, 182, 25, 51, 4, 98, 1, 3, 3, 3, 3]\n",
      "an adult and a child sitting down and both are biting their finger nails\n",
      "[0, 131, 1469, 29, 4, 46, 269, 116, 29, 372, 198, 418, 470, 932, 2696, 1, 3, 3, 3, 3]\n",
      "a crowd of people\n",
      "[0, 4, 70, 112, 152, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a boy plays with a car\n",
      "[0, 4, 13, 209, 63, 4, 765, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "four girls play volleyball\n",
      "[0, 568, 764, 232, 952, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a balck and tan dog running through the snow\n",
      "[0, 4, 1346, 29, 1023, 6, 91, 165, 21, 92, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a brown dog is fetching a ball\n",
      "[0, 4, 32, 6, 25, 328, 4, 164, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a big tan dog jumps in the water\n",
      "[0, 4, 280, 1023, 6, 14, 42, 21, 15, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a black and white dog is carrying a stick in a field\n",
      "[0, 4, 5, 29, 85, 6, 25, 225, 4, 86, 42, 4, 62, 1, 3, 3, 3, 3, 3, 3]\n",
      "a man is cycling on the road\n",
      "[0, 4, 41, 25, 3383, 23, 21, 302, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a couple of smiling little boys ride together in a plastic chairswing one on the others lap\n",
      "[0, 4, 102, 112, 278, 274, 467, 54, 416, 42, 4, 915, 916, 205, 23, 21, 64, 917, 1, 3]\n",
      "a crowd of people wearing jackets and holding signs\n",
      "[0, 4, 70, 112, 152, 57, 1168, 29, 47, 1689, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a black and white dog jumping into the air\n",
      "[0, 4, 5, 29, 85, 6, 7, 11, 21, 308, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a little dog carries a small stick in his mouth\n",
      "[0, 4, 274, 6, 685, 4, 55, 86, 42, 73, 87, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a girl touches the fountain with her foot\n",
      "[0, 4, 56, 1729, 21, 310, 63, 185, 780, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "two dogs are tugging at a piece of white material\n",
      "[0, 18, 33, 198, 2830, 139, 4, 463, 112, 85, 2831, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a brown and black dog fetching a blue toy\n",
      "[0, 4, 32, 29, 5, 6, 328, 4, 31, 329, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a crowd is watching a dog climb up a staircase\n",
      "[0, 4, 70, 25, 202, 4, 6, 1197, 28, 4, 1409, 1, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "a man plays a song on the guitar for his cat\n",
      "[0, 4, 41, 209, 4, 3671, 23, 21, 1252, 247, 73, 668, 1, 3, 3, 3, 3, 3, 3, 3]\n",
      "a big tricolored and a smaller puppy with light blue eyes are playing together\n",
      "[0, 4, 280, 411, 29, 4, 412, 413, 63, 414, 31, 415, 198, 387, 416, 1, 3, 3, 3, 3]\n",
      "a dog jumping in the air to retrieve a stick from a man\n",
      "[0, 4, 6, 7, 42, 21, 308, 48, 1708, 4, 86, 8, 4, 41, 1, 3, 3, 3, 3, 3]\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    conv = batch_capt_transform(y)\n",
    "    for i in range(len(y)):\n",
    "        print(y[i])\n",
    "        print(conv[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы использовать pretrained cnn с нашими данными можно действовать несколькими способами:\n",
    "1. Дообучать всю сетку на наших данных\n",
    "2. Дообучать только последний полносвязный слой (а до этого всю сетку заморозить).\n",
    "\n",
    "Пока запускала ноутбук локально, поэтому выбрала второй вариант. Но опыт написания последней домашки показывает, что так ничего не научим, поэтому при переходе на колаб параметры разморожу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size=1024):\n",
    "        super().__init__()\n",
    "        self.densenet = torchvision.models.densenet121(pretrained=True)\n",
    "        \n",
    "        for param in self.densenet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.densenet.classifier = nn.Sequential(nn.Linear(in_features=1024, out_features=1024), nn.ReLU())\n",
    "        self.embed = nn.Linear(in_features=1024, out_features=embed_size)\n",
    "        \n",
    "    def forward(self, images):\n",
    "        densenet_outputs = self.densenet(images)\n",
    "        embeddings = self.embed(densenet_outputs)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схема декодера похожа на ту, что в этой статье:\n",
    "https://arxiv.org/pdf/1411.4555.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(input_size = embed_size,hidden_size = hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    def forward(self, features, captions):\n",
    "        captions = captions[:, :-1] # убираем <end>, он не подается как x_t\n",
    "        embed = self.embedding_layer(captions)\n",
    "        embed = torch.cat((features.unsqueeze(1), embed), dim=1)\n",
    "        lstm_outputs, hidden = self.lstm(embed)\n",
    "        return self.linear(lstm_outputs)\n",
    "    \n",
    "    def sample(self, features, captions=None, seq_len=20):\n",
    "        output_sentence = []\n",
    "        for i in range(seq_len):\n",
    "            lstm_outputs, hidden = self.lstm(features, captions)\n",
    "            lstm_outputs = lstm_outputs.squeeze(1)\n",
    "            out = self.linear(lstm_outputs)\n",
    "            out = out.max(1)[1]\n",
    "            output_sentence.append(out.item())\n",
    "            features = self.embedding_layer(last_pick).unsqueeze(1)\n",
    "        \n",
    "        return output_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 1024\n",
    "hidden_size = 1024\n",
    "vocab_size = len(ind2word)\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, len(ind2word))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(list(decoder.parameters()) + list(encoder.embed.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Train*************\n",
      "Epoch: [1/1], Step: 0, Loss: 8.295736312866211, Perplexity: 4006.7523839870137\n",
      "Epoch: [1/1], Step: 1, Loss: 6.209278106689453, Perplexity: 497.3420937351666\n",
      "Epoch: [1/1], Step: 2, Loss: 5.2470526695251465, Perplexity: 190.00543357697808\n",
      "Epoch: [1/1], Step: 3, Loss: 4.984119415283203, Perplexity: 146.0748870610914\n",
      "Epoch: [1/1], Step: 4, Loss: 4.66823673248291, Perplexity: 106.50977153925982\n",
      "Epoch: [1/1], Step: 5, Loss: 4.0283708572387695, Perplexity: 56.16932881151616\n",
      "Epoch: [1/1], Step: 6, Loss: 3.5147347450256348, Perplexity: 33.60701231433022\n",
      "Epoch: [1/1], Step: 7, Loss: 3.2462894916534424, Perplexity: 25.69482196533845\n",
      "Epoch: [1/1], Step: 8, Loss: 3.0619912147521973, Perplexity: 21.370067217755498\n",
      "Epoch: [1/1], Step: 9, Loss: 3.121738910675049, Perplexity: 22.68579393352146\n",
      "Epoch: [1/1], Step: 10, Loss: 3.0718846321105957, Perplexity: 21.582539517227964\n",
      "Epoch: [1/1], Step: 11, Loss: 3.2466368675231934, Perplexity: 25.7037492769433\n",
      "Epoch: [1/1], Step: 12, Loss: 3.1244723796844482, Perplexity: 22.74788967792465\n",
      "Epoch: [1/1], Step: 13, Loss: 2.91095232963562, Perplexity: 18.37428861713307\n",
      "Epoch: [1/1], Step: 14, Loss: 3.077803373336792, Perplexity: 21.710659764910396\n",
      "Epoch: [1/1], Step: 15, Loss: 3.090601682662964, Perplexity: 21.99030518145517\n",
      "Epoch: [1/1], Step: 16, Loss: 2.740180253982544, Perplexity: 15.489776938693941\n",
      "Epoch: [1/1], Step: 17, Loss: 3.0593550205230713, Perplexity: 21.313805760526957\n",
      "Epoch: [1/1], Step: 18, Loss: 2.890103340148926, Perplexity: 17.99516912892447\n",
      "Epoch: [1/1], Step: 19, Loss: 3.0791964530944824, Perplexity: 21.740925521967092\n",
      "Epoch: [1/1], Step: 20, Loss: 3.0285472869873047, Perplexity: 20.667187279170584\n",
      "Epoch: [1/1], Step: 21, Loss: 2.9625511169433594, Perplexity: 19.34726598916333\n",
      "Epoch: [1/1], Step: 22, Loss: 3.0078601837158203, Perplexity: 20.244035029518894\n",
      "Epoch: [1/1], Step: 23, Loss: 2.8158440589904785, Perplexity: 16.707271753507914\n",
      "Epoch: [1/1], Step: 24, Loss: 2.872690200805664, Perplexity: 17.6845291988181\n",
      "Epoch: [1/1], Step: 25, Loss: 2.782172679901123, Perplexity: 16.15408049366052\n",
      "Epoch: [1/1], Step: 26, Loss: 2.814854145050049, Perplexity: 16.690741175567243\n",
      "Epoch: [1/1], Step: 27, Loss: 2.797670841217041, Perplexity: 16.406389148971357\n",
      "Epoch: [1/1], Step: 28, Loss: 2.6731715202331543, Perplexity: 14.485838546607594\n",
      "Epoch: [1/1], Step: 29, Loss: 3.076626777648926, Perplexity: 21.68513011823159\n",
      "Epoch: [1/1], Step: 30, Loss: 2.629523277282715, Perplexity: 13.867157537100715\n",
      "Epoch: [1/1], Step: 31, Loss: 2.890108108520508, Perplexity: 17.99525493678214\n",
      "Epoch: [1/1], Step: 32, Loss: 2.7023682594299316, Perplexity: 14.915012550429203\n",
      "Epoch: [1/1], Step: 33, Loss: 2.9530625343322754, Perplexity: 19.164556057494714\n",
      "Epoch: [1/1], Step: 34, Loss: 2.8231611251831055, Perplexity: 16.829968308809814\n",
      "Epoch: [1/1], Step: 35, Loss: 2.6925137042999268, Perplexity: 14.768753579160414\n",
      "Epoch: [1/1], Step: 36, Loss: 2.722867250442505, Perplexity: 15.223910489973486\n",
      "Epoch: [1/1], Step: 37, Loss: 2.8581933975219727, Perplexity: 17.430009377168975\n",
      "Epoch: [1/1], Step: 38, Loss: 2.6255736351013184, Perplexity: 13.812495246060795\n",
      "Epoch: [1/1], Step: 39, Loss: 2.717712163925171, Perplexity: 15.145631854189432\n",
      "Epoch: [1/1], Step: 40, Loss: 2.545257091522217, Perplexity: 12.746504683146744\n",
      "Epoch: [1/1], Step: 41, Loss: 2.6208624839782715, Perplexity: 13.747575536924609\n",
      "Epoch: [1/1], Step: 42, Loss: 2.5741610527038574, Perplexity: 13.12030529529741\n",
      "Epoch: [1/1], Step: 43, Loss: 2.6796677112579346, Perplexity: 14.580247638699845\n",
      "Epoch: [1/1], Step: 44, Loss: 2.629218578338623, Perplexity: 13.862932872499712\n",
      "Epoch: [1/1], Step: 45, Loss: 2.4937691688537598, Perplexity: 12.106822889544057\n",
      "Epoch: [1/1], Step: 46, Loss: 2.3301920890808105, Perplexity: 10.279916003016144\n",
      "Epoch: [1/1], Step: 47, Loss: 2.4735422134399414, Perplexity: 11.864398739182036\n",
      "Epoch: [1/1], Step: 48, Loss: 2.522369861602783, Perplexity: 12.458085646189392\n",
      "Epoch: [1/1], Step: 49, Loss: 2.821881055831909, Perplexity: 16.808438564918596\n",
      "Epoch: [1/1], Step: 50, Loss: 2.600064754486084, Perplexity: 13.464609900667218\n",
      "Epoch: [1/1], Step: 51, Loss: 2.478482961654663, Perplexity: 11.923162795734447\n",
      "Epoch: [1/1], Step: 52, Loss: 2.4731550216674805, Perplexity: 11.85980583083057\n",
      "Epoch: [1/1], Step: 53, Loss: 2.6547820568084717, Perplexity: 14.221886158282736\n",
      "Epoch: [1/1], Step: 54, Loss: 2.4670333862304688, Perplexity: 11.78742619009924\n",
      "Epoch: [1/1], Step: 55, Loss: 2.6303350925445557, Perplexity: 13.878419677998094\n",
      "Epoch: [1/1], Step: 56, Loss: 2.2081449031829834, Perplexity: 9.098821532221157\n",
      "Epoch: [1/1], Step: 57, Loss: 2.5495800971984863, Perplexity: 12.801727172811185\n",
      "Epoch: [1/1], Step: 58, Loss: 2.6810848712921143, Perplexity: 14.600924830926502\n",
      "Epoch: [1/1], Step: 59, Loss: 2.7117764949798584, Perplexity: 15.055998677132239\n",
      "Epoch: [1/1], Step: 60, Loss: 2.436161518096924, Perplexity: 11.429086097055231\n",
      "Epoch: [1/1], Step: 61, Loss: 2.6248958110809326, Perplexity: 13.803135977328472\n",
      "Epoch: [1/1], Step: 62, Loss: 2.45811128616333, Perplexity: 11.68272536426807\n",
      "Epoch: [1/1], Step: 63, Loss: 2.6482656002044678, Perplexity: 14.129511160024611\n",
      "Epoch: [1/1], Step: 64, Loss: 2.4594523906707764, Perplexity: 11.698403630660351\n",
      "Epoch: [1/1], Step: 65, Loss: 2.5221879482269287, Perplexity: 12.455819559894762\n",
      "Epoch: [1/1], Step: 66, Loss: 2.4407429695129395, Perplexity: 11.481568029652266\n",
      "Epoch: [1/1], Step: 67, Loss: 2.584991931915283, Perplexity: 13.263182081059721\n",
      "Epoch: [1/1], Step: 68, Loss: 2.715357780456543, Perplexity: 15.110015173044948\n",
      "Epoch: [1/1], Step: 69, Loss: 2.5936713218688965, Perplexity: 13.378799428584875\n",
      "Epoch: [1/1], Step: 70, Loss: 2.461137533187866, Perplexity: 11.718133727343877\n",
      "Epoch: [1/1], Step: 71, Loss: 2.6746246814727783, Perplexity: 14.506904107828532\n",
      "Epoch: [1/1], Step: 72, Loss: 2.432420492172241, Perplexity: 11.386409466633697\n",
      "Epoch: [1/1], Step: 73, Loss: 2.3450496196746826, Perplexity: 10.433790435991687\n",
      "Epoch: [1/1], Step: 74, Loss: 2.413717269897461, Perplexity: 11.175426104144227\n",
      "Epoch: [1/1], Step: 75, Loss: 2.4418387413024902, Perplexity: 11.49415610356755\n",
      "Epoch: [1/1], Step: 76, Loss: 2.425931930541992, Perplexity: 11.312767221555236\n",
      "Epoch: [1/1], Step: 77, Loss: 2.6436281204223633, Perplexity: 14.06413753927281\n",
      "Epoch: [1/1], Step: 78, Loss: 2.424333095550537, Perplexity: 11.294694425030881\n",
      "Epoch: [1/1], Step: 79, Loss: 2.278499126434326, Perplexity: 9.76201785441532\n",
      "Epoch: [1/1], Step: 80, Loss: 2.3955001831054688, Perplexity: 10.973685538704899\n",
      "Epoch: [1/1], Step: 81, Loss: 2.438166379928589, Perplexity: 11.452022820339769\n",
      "Epoch: [1/1], Step: 82, Loss: 2.547657012939453, Perplexity: 12.777132029642972\n",
      "Epoch: [1/1], Step: 83, Loss: 2.4329769611358643, Perplexity: 11.392747413380762\n",
      "Epoch: [1/1], Step: 84, Loss: 2.3358635902404785, Perplexity: 10.338384203057146\n",
      "Epoch: [1/1], Step: 85, Loss: 2.5671439170837402, Perplexity: 13.02856060259873\n",
      "Epoch: [1/1], Step: 86, Loss: 2.4226481914520264, Perplexity: 11.275679971366523\n",
      "Epoch: [1/1], Step: 87, Loss: 2.4578802585601807, Perplexity: 11.680026643980353\n",
      "Epoch: [1/1], Step: 88, Loss: 2.383876323699951, Perplexity: 10.846867446585298\n",
      "Epoch: [1/1], Step: 89, Loss: 2.173765182495117, Perplexity: 8.79132273782891\n",
      "Epoch: [1/1], Step: 90, Loss: 2.2936348915100098, Perplexity: 9.910897323418641\n",
      "Epoch: [1/1], Step: 91, Loss: 2.5115177631378174, Perplexity: 12.323620209791592\n",
      "Epoch: [1/1], Step: 92, Loss: 2.338740110397339, Perplexity: 10.36816558644624\n",
      "Epoch: [1/1], Step: 93, Loss: 2.368307590484619, Perplexity: 10.679303226983496\n",
      "Epoch: [1/1], Step: 94, Loss: 2.550036907196045, Perplexity: 12.807576465675755\n",
      "Epoch: [1/1], Step: 95, Loss: 2.1075286865234375, Perplexity: 8.22788246166041\n",
      "Epoch: [1/1], Step: 96, Loss: 2.3058080673217773, Perplexity: 10.032281736937975\n",
      "***********Validation*************\n",
      "Epoch: [1/1], Step: 97, Loss: 2.4272894859313965, Perplexity: 11.328135358854507\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.2909772396087646, Perplexity: 9.884592578214844\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.5299649238586426, Perplexity: 12.553065815834874\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.3605875968933105, Perplexity: 10.597176491332082\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.4852283000946045, Perplexity: 12.00386042449933\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/1], Step: 97, Loss: 2.4316515922546387, Perplexity: 11.377657822333475\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.477728843688965, Perplexity: 11.91417471392518\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.3168039321899414, Perplexity: 10.143204077144656\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.2650763988494873, Perplexity: 9.631860436057192\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.379883289337158, Perplexity: 10.803641890142043\n",
      "None\n",
      "Epoch: [1/1], Step: 97, Loss: 2.3781332969665527, Perplexity: 10.78475213254616\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "    step = 0\n",
    "    decoder.train()\n",
    "    encoder.train()\n",
    "    print('***********Train*************')\n",
    "    for images, captions in train_dataloader:\n",
    "        images = torch.Tensor(images).to(device)\n",
    "        captions = torch.Tensor(batch_capt_transform(captions)).long().to(device)\n",
    "        \n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "        \n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "        \n",
    "        loss = criterion(outputs.view(-1, len(ind2word)), captions.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "        print(f'Epoch: [{epoch}/{num_epochs}], Step: {step}, Loss: {loss.item()}, Perplexity: {np.exp(loss.item())}')\n",
    "        step += 1\n",
    "        \n",
    "    # Validate\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    print('***********Validation*************')\n",
    "    with torch.no_grad():\n",
    "        for images, captions in valid_dataloader:\n",
    "            images = torch.Tensor(images).to(device)\n",
    "            captions = torch.Tensor(batch_capt_transform(captions)).long().to(device)\n",
    "\n",
    "            features = encoder(images)\n",
    "            outputs = decoder(features, captions)\n",
    "        \n",
    "            loss = criterion(outputs.view(-1, len(ind2word)), captions.view(-1))\n",
    "            print(print(f'Epoch: [{epoch}/{num_epochs}], Step: {step}, Loss: {loss.item()}, Perplexity: {np.exp(loss.item())}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну. видно что оно чему-то учится. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
