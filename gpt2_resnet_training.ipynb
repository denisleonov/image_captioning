{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt2-resnet-training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bdae7d6d207488e928540e238215a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_563daf79dc574ce5b48bc5da4ae5be19",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c3dfb3f652244739b1324573c11aa7ab",
              "IPY_MODEL_a0c167c04aef4da997b42577ad96bed4"
            ]
          }
        },
        "563daf79dc574ce5b48bc5da4ae5be19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3dfb3f652244739b1324573c11aa7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c59c2ddd72b74d6e8cc7defe3432b2f3",
            "_dom_classes": [],
            "description": "loss:3.8891:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25925,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83e4f949d05140e2830276a93616e88c"
          }
        },
        "a0c167c04aef4da997b42577ad96bed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5b2041a670049d7829d10bef17b2095",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7/25925 [01:23&lt;75:12:22, 10.45s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adb81fa58f1d48da8d8fdf2a7d4409b6"
          }
        },
        "c59c2ddd72b74d6e8cc7defe3432b2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83e4f949d05140e2830276a93616e88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5b2041a670049d7829d10bef17b2095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adb81fa58f1d48da8d8fdf2a7d4409b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZTQ4SPQz-86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb9xbkAR0AOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
        "from transformers.optimization import AdamW\n",
        "\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from IPython.display import display\n",
        "from multiprocessing.pool import ThreadPool\n",
        "\n",
        "from collections import namedtuple\n",
        "from time import perf_counter\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_vrmvQg0SgI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7Gxsxe0U1i",
        "colab_type": "code",
        "outputId": "a9700391-7102-4ab4-8fd6-bf18d1aec2ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMuyqz8a0wjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r drive/My\\ Drive/image_captioning/* ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO1xbGpL00nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "     transforms.Resize((224, 224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "class GCCDataset(Dataset):\n",
        "    def __init__(self, path='data/Train_GCC-training.tsv', tokenizer=None, max_length=512, timeout=2):\n",
        "        self.data = pd.read_csv(path, sep='\\t', header=None, names=['desc', 'url'])\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        desc, url = self.data.iloc[idx]\n",
        "        text_tok_ids = self.tokenizer.encode(desc, max_length=self.max_length)\n",
        "\n",
        "        return url, text_tok_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCUiqZhZ02CC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataloader(dataset, batch_size, pad_elem, img_transform, timeout=3, num_workers=4):\n",
        "    def pad(seq, max_len, pad_elem):\n",
        "        return seq + [pad_elem] * max(0, max_len - len(seq))\n",
        "\n",
        "    def get_image_from_url(url):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=timeout)\n",
        "            if response.ok and response.url == url:\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "                return img_transform(img)\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            return None\n",
        "    \n",
        "    def collate_fn(batch_data):\n",
        "        list_urls, list_ids = list(zip(*batch_data))\n",
        "\n",
        "        list_imgs = ThreadPool(num_workers).imap_unordered(get_image_from_url, list_urls) \n",
        "        list_imgs, list_ids = list(zip(*[(img, ids) for img, ids in zip(list_imgs, list_ids) \n",
        "                                                    if img is not None]))\n",
        "        \n",
        "        batch_img = torch.stack(list_imgs, 0)        \n",
        "\n",
        "        batch_len = max(map(len, list_ids))\n",
        "        batch_ids = torch.tensor(\n",
        "            [pad(ids, batch_len, pad_elem) \n",
        "             for ids in list_ids]\n",
        "        ).long()\n",
        "        batch_mask = batch_ids.ne(pad_elem).int()\n",
        "\n",
        "        return batch_img, batch_ids, batch_mask\n",
        "\n",
        "    return DataLoader(\n",
        "        dataset=dataset, batch_size=batch_size, shuffle=True,\n",
        "        collate_fn=collate_fn, pin_memory=True, num_workers=0 \n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WalaxU0W02vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataloader(dataset, batch_size, pad_elem, img_transform, timeout=3, num_workers=4):\n",
        "    def pad(seq, max_len, pad_elem):\n",
        "        return seq + [pad_elem] * max(0, max_len - len(seq))\n",
        "\n",
        "    def get_image_from_url(url):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=timeout)\n",
        "            if response.ok and response.url == url:\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "                return img_transform(img)\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            return None\n",
        "    \n",
        "    def collate_fn(batch_data):\n",
        "        list_urls, list_ids = list(zip(*batch_data))\n",
        "\n",
        "        list_imgs = ThreadPool(num_workers).imap_unordered(get_image_from_url, list_urls) \n",
        "        list_imgs, list_ids = list(zip(*[(img, ids) for img, ids in zip(list_imgs, list_ids) \n",
        "                                                    if img is not None]))\n",
        "        \n",
        "        batch_img = torch.stack(list_imgs, 0)        \n",
        "\n",
        "        batch_len = max(map(len, list_ids))\n",
        "        batch_ids = torch.tensor(\n",
        "            [pad(ids, batch_len, pad_elem) \n",
        "             for ids in list_ids]\n",
        "        ).long()\n",
        "        batch_mask = batch_ids.ne(pad_elem).int()\n",
        "\n",
        "        return batch_img, batch_ids, batch_mask\n",
        "\n",
        "    return DataLoader(\n",
        "        dataset=dataset, batch_size=batch_size, shuffle=True,\n",
        "        collate_fn=collate_fn, pin_memory=True, num_workers=0 \n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWimCj962PIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, cnn, embed_size):\n",
        "        super().__init__()\n",
        "        self.cnn = cnn\n",
        "        self.embed_size = embed_size\n",
        "        _, last_module = list(cnn.named_children())[-1]\n",
        "        self.proj = nn.Linear(last_module.out_features, embed_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        return self.proj(x)\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        self.cnn.eval()\n",
        "        self.proj.train(mode)\n",
        "        for param in self.cnn.parameters():\n",
        "            param.requires_grad_(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Nm3DhE07Oe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPECIAL_TOKENS = ('img', 'desc', 'pad')\n",
        "SpecialIds = namedtuple('speacil_ids', SPECIAL_TOKENS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnfeYmYh08yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Image2TextDescriptor(nn.Module):\n",
        "    def __init__(self, pretrained_model_text='gpt2', \n",
        "                     pretrained_model_image='resnet18'):\n",
        "        super().__init__()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        self.tokenizer, self.special_ids = self._build_tokenizer(pretrained_model_text)\n",
        "        self.gpt2 = self._build_gpt2(len(self.tokenizer), pretrained_model_text)\n",
        "\n",
        "        cnn = self._build_cnn(pretrained_model_image)\n",
        "        self.embedding = Embedding(cnn, self.gpt2.config.hidden_size)#.to(device)\n",
        "        self.to(device)\n",
        "\n",
        "    def save(self, path='weights/model_full_trained'):\n",
        "        state = {\n",
        "            'gpt_dict': self.gpt2.state_dict(),\n",
        "            'projection_dict': self.embedding.proj.state_dict(),\n",
        "            'tokenizer': self.tokenizer,\n",
        "        }\n",
        "        torch.save(state, path)\n",
        "        print('!!! model is saved !!!')\n",
        "\n",
        "    def load(self, path='weights/model_full_trained'):\n",
        "        state = torch.load(path)\n",
        "        self.gpt2.load_state_dict(state['gpt_dict'])\n",
        "        self.embedding.proj.load_state_dict(state['projection_dict'])\n",
        "        self.tokenizer = state['tokenizer']\n",
        "        print('!!! model weights are loaded !!!')\n",
        "\n",
        "    def forward(self, img_data, text_tok_ids=None, attn_mask=None):\n",
        "        context_embeds = self.get_context_embeds(img_data)\n",
        "        labels_ids = None\n",
        "        if text_tok_ids is not None:\n",
        "            text_embeds = self.gpt2.transformer.wte(text_tok_ids)\n",
        "            full_embeds = torch.cat((context_embeds, text_embeds), dim=1)\n",
        "            if self.training:\n",
        "                labels_ids = self.get_labels(\n",
        "                    full_embeds.shape[:-1],\n",
        "                    context_embeds.size(1),\n",
        "                    text_tok_ids\n",
        "                ).to(self.device)\n",
        "        else:\n",
        "            full_embeds = context_embeds\n",
        "        \n",
        "        out = self.gpt2(inputs_embeds=full_embeds, labels=labels_ids, attention_mask=attn_mask)        \n",
        "        return out\n",
        "\n",
        "    def get_context_embeds(self, img_data):\n",
        "        img_tok_emb, desc_tok_emb = self.gpt2.transformer.wte(\n",
        "            torch.tensor([self.special_ids.img, self.special_ids.desc]).to(self.device)\n",
        "        )\n",
        "\n",
        "        img_embeds = self.embedding(img_data)[:, None, :] # new shape: (batch_size, seq_len, embed_size)\n",
        "        context_embeds = torch.cat((img_tok_emb.expand_as(img_embeds), \n",
        "                                    img_embeds, \n",
        "                                    desc_tok_emb.expand_as(img_embeds)), dim=1)\n",
        "        return context_embeds\n",
        "\n",
        "    def get_labels(self, shape, context_len, tok_ids):\n",
        "        labels_ids = torch.empty(shape, dtype=torch.long).fill_(-100) # -100 is mask value for labels in hugginface models\n",
        "        mask = (tok_ids == self.special_ids.pad)\n",
        "        labels_ids[:, context_len:] = tok_ids.masked_fill(mask, -100)\n",
        "\n",
        "        return labels_ids\n",
        "\n",
        "    def _build_tokenizer(self, pretrained_model):\n",
        "        special_dct = {t: f\"<{t.upper()}>\" for t in SPECIAL_TOKENS}\n",
        "        tokenizer = AutoTokenizer.from_pretrained(pretrained_model)\n",
        "        tokenizer.add_special_tokens({'additional_special_tokens': list(special_dct.values())})\n",
        "        special_ids = SpecialIds(**{k: tokenizer.encode(v)[0] for k, v in special_dct.items()})\n",
        "        \n",
        "        return tokenizer, special_ids\n",
        "\n",
        "    def _build_gpt2(self, vocab_size, pretrained_model):\n",
        "        gpt2 = AutoModelWithLMHead.from_pretrained(pretrained_model)\n",
        "        gpt2.resize_token_embeddings(vocab_size)\n",
        "        \n",
        "        return gpt2\n",
        "\n",
        "    def _build_cnn(self, pretrained_model):\n",
        "        if pretrained_model == 'resnet18':\n",
        "            return models.resnet18(pretrained=True)\n",
        "        else:\n",
        "            raise ValueError(f'{pretrained_model} is not supported yet :(')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNLpnDjswBYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNY5f2tlwFjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = Counter([str(b) for b in [1, 2, 5, 1, 9, 19, 1, 1, 4, 5, 5]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxleSFEKwLZ-",
        "colab_type": "code",
        "outputId": "bf70bf08-14a3-4087-fdba-904927a18054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(sorted(c.items(), key=lambda x: x[-1], reverse=True))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 4), ('5', 3), ('2', 1), ('9', 1), ('19', 1), ('4', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8X_bZwFLvIGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def debug_memory():\n",
        "    import collections, gc, resource, torch\n",
        "    print('maxrss = {}'.format(\n",
        "        resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\n",
        "    tensors = collections.Counter((str(o.device), o.dtype, tuple(o.shape))\n",
        "                                  for o in gc.get_objects()\n",
        "                                  if torch.is_tensor(o))\n",
        "    \n",
        "    for line in sorted(tensors.items(), key=lambda x: (x[1], x[0][-1]), reverse=True):\n",
        "        print('{}\\t\\t{}'.format(*line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4utdS9W0_Lp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = []\n",
        "\n",
        "def train_epoch(dataloader, model, optimizer, save_interval=20):\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), leave=False)\n",
        "    for idx_batch, batch in pbar:\n",
        "        torch.cuda.empty_cache()\n",
        "        #print('\\t real size of the batch', len(batch[1]))\n",
        "        #print()\n",
        "        imgs, ids, mask = [x.to(model.device) for x in batch]\n",
        "        '''print('#' * 10 + str(idx_batch) + '#' * 10)\n",
        "        print('IMGS: ', imgs)\n",
        "        print('IDS: ', ids)\n",
        "        print('MASK: ', mask)'''\n",
        "\n",
        "        loss, *_ = model(imgs, ids)#, attn_mask=mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        '''print('loss: ', loss.item())\n",
        "        print()\n",
        "        print()'''\n",
        "        losses.append(loss.item())\n",
        "        pbar.set_description(f'loss:{loss.item():.4f}')\n",
        "        \n",
        "        debug_memory()\n",
        "        print('#'*50)\n",
        "        if (idx_batch + 1) % save_interval == 0:\n",
        "            model.save('weights/temp_weights')\n",
        "            print(torch.cuda.memory_summary())\n",
        "\n",
        "    model.save()\n",
        "\n",
        "\n",
        "def train(model, dataloader, n_epochs=5, batch_size=16, lr=1e-3):\n",
        "    model.load('weights/temp_weights')\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(\n",
        "        [param for param in model.parameters()\n",
        "               if param.requires_grad], \n",
        "        lr=lr\n",
        "    )\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_epoch(dataloader, model, optimizer)\n",
        "        print(f'Epoch #{epoch} finished')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN5IfSf-1FCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "descriptor = Image2TextDescriptor()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je6LRNKJ1GJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='data/Train_GCC-training.tsv'\n",
        "batch_size = 128\n",
        "num_workers = 16 # 14 ~ 5 sec; 4 ~ 11 sec; 6 ~ 9 sec; 16 ~ 4 sec\n",
        "timeout = 2\n",
        "gcc_dataset = GCCDataset(path=path,  \n",
        "                         tokenizer=descriptor.tokenizer, \n",
        "                         max_length=descriptor.gpt2.config.n_positions - 10)\n",
        "dataloader = get_dataloader(gcc_dataset, batch_size, descriptor.special_ids.pad, \n",
        "                            img_transform=transform, \n",
        "                            timeout=timeout, \n",
        "                            num_workers=num_workers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc_GruSF1HpV",
        "colab_type": "code",
        "outputId": "9277f89e-f576-45d9-cc16-dba1ebb3759d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6bdae7d6d207488e928540e238215a21",
            "563daf79dc574ce5b48bc5da4ae5be19",
            "c3dfb3f652244739b1324573c11aa7ab",
            "a0c167c04aef4da997b42577ad96bed4",
            "c59c2ddd72b74d6e8cc7defe3432b2f3",
            "83e4f949d05140e2830276a93616e88c",
            "e5b2041a670049d7829d10bef17b2095",
            "adb81fa58f1d48da8d8fdf2a7d4409b6"
          ]
        }
      },
      "source": [
        "train(descriptor, dataloader, lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!!! model weights are loaded !!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bdae7d6d207488e928540e238215a21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25925.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "maxrss = 4372024\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 71, 12, 25, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (71, 25, 50260))\t\t1\n",
            "('cpu', torch.int64, (71, 22))\t\t1\n",
            "('cpu', torch.int32, (71, 22))\t\t1\n",
            "('cuda:0', torch.int64, (71, 22))\t\t1\n",
            "('cuda:0', torch.int32, (71, 22))\t\t1\n",
            "('cpu', torch.float32, (71, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (71, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "##################################################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/distributed/distributed_c10d.py:102: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
            "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "maxrss = 4416472\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 75, 12, 31, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (75, 31, 50260))\t\t1\n",
            "('cpu', torch.int64, (75, 28))\t\t1\n",
            "('cpu', torch.int32, (75, 28))\t\t1\n",
            "('cuda:0', torch.int64, (75, 28))\t\t1\n",
            "('cuda:0', torch.int32, (75, 28))\t\t1\n",
            "('cpu', torch.float32, (75, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (75, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cpu', torch.int64, (71, 22))\t\t1\n",
            "('cpu', torch.int32, (71, 22))\t\t1\n",
            "('cpu', torch.float32, (71, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "##################################################\n",
            "maxrss = 4457028\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 69, 12, 32, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (69, 32, 50260))\t\t1\n",
            "('cpu', torch.int64, (69, 29))\t\t1\n",
            "('cpu', torch.int32, (69, 29))\t\t1\n",
            "('cuda:0', torch.int64, (69, 29))\t\t1\n",
            "('cuda:0', torch.int32, (69, 29))\t\t1\n",
            "('cpu', torch.float32, (69, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (69, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "##################################################\n",
            "maxrss = 4457292\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 68, 12, 25, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cpu', torch.int64, (69, 29))\t\t1\n",
            "('cpu', torch.int32, (69, 29))\t\t1\n",
            "('cpu', torch.float32, (69, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (68, 25, 50260))\t\t1\n",
            "('cpu', torch.int64, (68, 22))\t\t1\n",
            "('cpu', torch.int32, (68, 22))\t\t1\n",
            "('cuda:0', torch.int64, (68, 22))\t\t1\n",
            "('cuda:0', torch.int32, (68, 22))\t\t1\n",
            "('cpu', torch.float32, (68, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (68, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "##################################################\n",
            "maxrss = 4457380\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 62, 12, 34, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "('cuda:0', torch.float32, (62, 34, 50260))\t\t1\n",
            "('cpu', torch.int64, (62, 31))\t\t1\n",
            "('cpu', torch.int32, (62, 31))\t\t1\n",
            "('cuda:0', torch.int64, (62, 31))\t\t1\n",
            "('cuda:0', torch.int32, (62, 31))\t\t1\n",
            "('cpu', torch.float32, (62, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (62, 3, 224, 224))\t\t1\n",
            "##################################################\n",
            "maxrss = 4457728\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 68, 12, 30, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (68, 30, 50260))\t\t1\n",
            "('cpu', torch.int64, (68, 27))\t\t1\n",
            "('cpu', torch.int32, (68, 27))\t\t1\n",
            "('cuda:0', torch.int64, (68, 27))\t\t1\n",
            "('cuda:0', torch.int32, (68, 27))\t\t1\n",
            "('cpu', torch.float32, (68, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (68, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "('cpu', torch.int64, (62, 31))\t\t1\n",
            "('cpu', torch.int32, (62, 31))\t\t1\n",
            "('cpu', torch.float32, (62, 3, 224, 224))\t\t1\n",
            "##################################################\n",
            "maxrss = 4457764\n",
            "('cuda:0', torch.float32, (768,))\t\t375\n",
            "('cuda:0', torch.float32, (3072, 768))\t\t60\n",
            "('cuda:0', torch.float32, (3072,))\t\t60\n",
            "('cuda:0', torch.float32, (2304,))\t\t60\n",
            "('cuda:0', torch.float32, (768, 3072))\t\t60\n",
            "('cuda:0', torch.float32, (768, 2304))\t\t60\n",
            "('cuda:0', torch.float32, (768, 768))\t\t60\n",
            "('cuda:0', torch.float32, (512,))\t\t20\n",
            "('cuda:0', torch.float32, (256,))\t\t20\n",
            "('cuda:0', torch.float32, (128,))\t\t20\n",
            "('cuda:0', torch.float32, (64,))\t\t20\n",
            "('cuda:0', torch.int64, ())\t\t20\n",
            "('cuda:0', torch.float32, ())\t\t14\n",
            "('cuda:0', torch.float32, (2, 74, 12, 31, 64))\t\t12\n",
            "('cuda:0', torch.float32, (2, 72, 12, 27, 64))\t\t12\n",
            "('cuda:0', torch.uint8, (1, 1, 1024, 1024))\t\t12\n",
            "('cuda:0', torch.float32, (50260, 768))\t\t5\n",
            "('cuda:0', torch.float32, (1024, 768))\t\t5\n",
            "('cuda:0', torch.float32, (768, 1000))\t\t5\n",
            "('cuda:0', torch.float32, (64, 64, 3, 3))\t\t4\n",
            "('cuda:0', torch.float32, (512, 512, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (256, 256, 3, 3))\t\t3\n",
            "('cuda:0', torch.float32, (128, 128, 3, 3))\t\t3\n",
            "('cpu', torch.float32, (3, 224, 224))\t\t2\n",
            "('cuda:0', torch.float32, (1000, 512))\t\t1\n",
            "('cuda:0', torch.float32, (1000,))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (512, 256, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (256, 128, 1, 1))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 3, 3))\t\t1\n",
            "('cuda:0', torch.float32, (128, 64, 1, 1))\t\t1\n",
            "('cpu', torch.int64, (79, 31))\t\t1\n",
            "('cpu', torch.int32, (79, 31))\t\t1\n",
            "('cpu', torch.float32, (79, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (74, 31, 50260))\t\t1\n",
            "('cpu', torch.int64, (74, 28))\t\t1\n",
            "('cpu', torch.int32, (74, 28))\t\t1\n",
            "('cuda:0', torch.int64, (74, 28))\t\t1\n",
            "('cuda:0', torch.int32, (74, 28))\t\t1\n",
            "('cpu', torch.float32, (74, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (74, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 27, 50260))\t\t1\n",
            "('cpu', torch.int64, (72, 24))\t\t1\n",
            "('cpu', torch.int32, (72, 24))\t\t1\n",
            "('cuda:0', torch.int64, (72, 24))\t\t1\n",
            "('cuda:0', torch.int32, (72, 24))\t\t1\n",
            "('cpu', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (72, 3, 224, 224))\t\t1\n",
            "('cuda:0', torch.float32, (64, 3, 7, 7))\t\t1\n",
            "##################################################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-c5990aed4a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescriptor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-da0edb8c1bf0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, n_epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch #{epoch} finished'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-da0edb8c1bf0>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, optimizer, save_interval)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print('\\t real size of the batch', len(batch[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-03d0f61b2c82>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch_data)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlist_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_image_from_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         list_imgs, list_ids = list(zip(*[(img, ids) for img, ids in zip(list_imgs, list_ids) \n\u001b[0m\u001b[1;32m     20\u001b[0m                                                     if img is not None]))\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-03d0f61b2c82>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlist_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mThreadPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_image_from_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_urls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         list_imgs, list_ids = list(zip(*[(img, ids) for img, ids in zip(list_imgs, list_ids) \n\u001b[0m\u001b[1;32m     20\u001b[0m                                                     if img is not None]))\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQG0Am2M1Jmt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp weights/temp_weights drive/My\\ Drive/image_captioning/weights/temp_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfDasrUQTMe4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(torch.cuda.memory_summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuuCnkB2iQl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}